# GAE 

### 使用

```
npm install

npm run docs:dev
```



### Quickstart

##### 1. 环境准备

- 确保以下组件和依赖已安装和配置：
  - Go, Java, Python
  - Kafka
  - Redis
  - MySQL
  - Elasticsearch
  - Parquet 文件支持

##### 2. 配置文件

- 根据各模块中`app.go`文件中相关环境变量。配置Kafka、Redis、MySQL和Elasticsearch连接信息。
- 配置爬虫模块和分析模块的相关参数（如爬取频率、API Token等）。

##### 3. 启动步骤

1. **启动Kafka和Redis**

2. **启动存储模块**
   启动 `gae-backend-storage` 模块，用于准备存储环境。

   ```
   go run gae-backend-storage/cmd/main.go
   ```

3. **启动数据爬虫模块**
   启动 `gae-backend-crawl` 模块，开始爬取GitHub数据。

   ```
   go run gae-backend-crawl/cmd/main.go
   ```

4. **启动数据清洗模块**
   启动 `gae-backend-analysis` 模块，对爬取到的数据进行清洗和分析。

   ```
   go run gae-backend-analysis/cmd/main.go
   ```

5. **启动Web接口模块**
   启动 `gae-backend-web` 模块，提供RESTful API服务。

   ```
   go run gae-backend-web/cmd/main.go
   ```

6. **测试API服务**
   通过提供的API接口测试开发者数据查询、筛选和排名功能。



---



### 关于项目架构设计

#### 1. 项目背景和目标

**项目概述**
本项目致力于对GitHub数据进行爬取、分析并对开发者进行多维度的评价和评级。通过综合评估开发者的技术能力、所在国家和领域，为开发者建立全面的TalentRank评分体系，辅助精准的开发者搜索和筛选。

**业务需求**

- 爬取GitHub上的开发者数据，包括贡献、项目及社交网络信息。
- 对开发者的技术能力进行评级，提供基于项目重要性和贡献度的TalentRank评分。
- 通过爬取数据和网络关系推测开发者的国家/地区信息。
- 允许基于开发者领域和国家进行筛选和排序。
- 实现推测开发者之Nation并且给出其置信度



------



#### 2. 主要架构概述

**系统架构图**
该系统由四个主要模块构成，模块间通过消息队列进行解耦和数据传输。系统架构具备水平扩展性，并支持大数据组件和微服务架构的集合。
![GAE ARCHITECTURE](https://github.com/user-attachments/assets/5c5f8dc4-f03a-41e1-8ce5-39a44866dc37)

**架构风格**
采用分层架构，可结合微服务和大数据组件拓展。各模块独立运行，具备模块化设计，易于扩展和维护。



------



#### 3. 系统组件说明

##### 后端：
 `packages/back`
 
- **gae-backend-crawl（爬虫模块）**
  爬取GitHub开发者数据，包括贡献、项目、社交网络等信息。爬取的数据会通过Kafka传递至其他模块进行进一步处理。
- **gae-backend-storage（存储模块）**
  负责将处理后的数据存储到不同的介质中，包括MySQL、Elasticsearch和Parquet文件。不同的存储介质用于不同的数据读取和查询场景。
- **gae-backend-web（Web接口模块）**
  提供Web接口用于接收外部请求，根据请求类型从不同的存储介质中获取数据并返回。
- **gae-backend-analysis（数据清洗模块）**
  处理和分析爬取的数据，生成开发者的TalentRank评分，推测国家/地区，并对领域进行分类。清洗后的数据传递至存储模块进行分层存储。

##### 算法：
 `packages/algorithm`

 
 根据数据的特征值及其重要程度，拟定权重进行建模，详见`algorithm`包内`README.md`
 
------

#### 4. 技术选型和理由

- **编程语言和框架**
  - 爬虫模块和Web接口模块主要使用Go语言，具备高效的并发处理能力。
  - Python用于数据分析和脚本性任务。
- **数据库**
  - **MySQL**：用于存储全量用户数据，支持结构化查询。
  - **Elasticsearch**：用于存储部分冗余的搜索所需数据，以便于快速查询和检索。
- **中间件**
  - **Kafka**：用于模块间数据传输的解耦。
  - **Redis**：用于缓存热点排行榜数据，提高读取性能。
- **文件存储**
  - 使用Parquet文件进行数据分片存储，支持大数据量的处理。
- **通信协议**
  - **gRPC**：用于实现异构项目间的高效通信和调度，提供强类型接口定义和轻量级高性能的通信方式，适用于跨模块或跨语言调用的高并发场景。



------



#### 5. 详细设计

- **模块设计**
  - **爬虫模块**：实现GitHub数据的批量爬取，通过调度器定期爬取和增量更新数据。支持多线程或协程并发爬取。
  - **存储模块**：实现数据的分层存储。使用MySQL存储基础数据，Elasticsearch存储用于搜索和过滤的数据，Parquet文件存储大规模数据分片。
  - **Web接口模块**：提供RESTful API供外部调用，根据请求类型查询对应存储介质的数据。
  - **数据清洗模块**：使用Flink进行数据清洗、合并和分析。生成开发者的TalentRank评分，并推测国家/地区及领域分类。
- **接口设计**
  Web接口提供查询开发者信息的API，支持按TalentRank排序、领域过滤、国家筛选等操作。
- **数据设计**
  - 数据模型包括开发者基本信息、贡献度信息、项目信息、社交网络信息等。
  - Parquet文件存储大规模数据，MySQL存储结构化数据，Elasticsearch存储索引数据。
- **异构调度**
  - 使用gRPC实现不同模块或异构系统之间的高效通信和调度。gRPC提供了高性能、强类型的接口定义和轻量级的通信方式，能够显著提升系统模块之间的数据交互效率，特别是在需要跨语言或高并发调用场景下。


---

#### 6. 启动运行流程
- **数据爬取阶段**
启动 `gae-backend-crawl` 模块，利用爬虫程序从GitHub收集开发者数据，包括项目、贡献记录和社交网络信息。爬取到的数据将通过Kafka消息队列传递到后续模块。

- **数据清洗和分析阶段**
启动 `gae-backend-analysis` 模块，使用Flink和Java对爬取的数据进行数据清洗和处理。包括生成开发者的TalentRank评分、推测国家/地区信息以及分类开发者的技术领域。

- **数据存储阶段**
启动 `gae-backend-storage` 模块，将清洗后的数据根据不同的用途存储到指定的介质中：

  - 使用 **MySQL** 存储全量用户数据。
  - 使用 **Elasticsearch** 存储用于搜索和快速查询的冗余数据。
  - 使用 **Parquet** 文件分片存储大规模数据。

- **Web接口服务阶段**
启动 `gae-backend-web` 模块，提供RESTful API供外部调用。Web接口层会根据外部请求类型从不同的存储介质中获取数据，响应开发者查询和筛选需求。

- **模块间高效通信**
利用 **gRPC** 进行异构模块间的高效通信和调度，实现跨模块或跨语言的高并发调用和数据交换。
